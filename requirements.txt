transformers>=4.36.0
torch>=2.0.0
peft>=0.7.0
datasets>=2.14.0
accelerate>=0.25.0
bitsandbytes>=0.41.0
langchain>=0.1.0
fastapi>=0.104.0
uvicorn>=0.24.0
pydantic>=2.4.0
scipy>=1.11.0
numpy>=1.24.0
tqdm>=4.66.0
sentencepiece>=0.1.99
protobuf>=3.20.0
einops>=0.7.0
safetensors>=0.4.0 